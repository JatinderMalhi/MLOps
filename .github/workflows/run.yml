name: Run Vertex AI Pipeline
on:
    push:
        branches: [ "main" ]
        paths:
            - 'pipelines/meta_forecasting_pipeline/src/**'
    workflow_dispatch:

permissions:
  contents: 'read'
  id-token: 'write'

env:
  PROJECT_ID: ${{ vars.PROJECT_ID }}
  SERVICE_ACCOUNT: ${{ vars.SERVICE_ACCOUNT_EMAIL }}
  REGION: ${{ vars.REGION }}
  DOCKER_REPO: ${{vars.DOCKER_REPO}}
  WORKLOAD_PROVIDER: ${{ vars.WORKLOAD_PROVIDER }}
  DATASET_ID: ${{ vars.META_DATASET_ID }}
  TABLE_ID: ${{ vars.META_TRAIN_TABLE_ID }}
  BUCKET_URI: ${{ vars.META_PIPELINE_BUCKET_URI }}
  LOCATION: ${{ vars.REGION }}

jobs:
  run-pipeline:
    name: 'Run Vertex AI Pipeline'
    runs-on: 'ubuntu-latest'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - id: auth
        uses: google-github-actions/auth@v2.0.0  
        with:
          workload_identity_provider: ${{ env.WORKLOAD_PROVIDER }}
          service_account: ${{ env.SERVICE_ACCOUNT }}
          create_credentials_file: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10.16' 

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r pipelines/meta_forecasting_pipeline/requirements.txt

      - name: Compile pipeline
        run: |
          python pipelines/meta_forecasting_pipeline/src/pipeline.py --compile-only --output data_pipeline.json

      - name: Upload pipeline spec to GCS
        run: |
          gsutil cp data_pipeline.json ${{ env.BUCKET_URI }}/compile_file_meta_training_model/pipeline.json
   
  